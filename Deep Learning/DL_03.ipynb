{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lH_N3f0E68V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform Regression Task using ANN\n",
        "\n",
        "Note: You are feel free to use any Regression ML dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "q6_AMG0zE_8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing neccsaries libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n"
      ],
      "metadata": {
        "id": "bVxI2kcCFAjW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California housing dataset\n",
        "california_housing = fetch_california_housing()\n"
      ],
      "metadata": {
        "id": "0RdZ3R73FNye"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features and target\n",
        "X, y = california_housing.data, california_housing.target"
      ],
      "metadata": {
        "id": "ePU1iSCwGILt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "tP-rqtm4GKJM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "iYSZ-IimGNxs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer with 64 neurons and ReLU activation\n",
        "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons and ReLU activation\n",
        "    Dense(1)  # Output layer with 1 neuron (for regression) and linear activation\n",
        "])\n"
      ],
      "metadata": {
        "id": "-iUgHf_IGQJI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "goukU6iJGSD7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai7rNrKnGU2u",
        "outputId": "c9f661e7-3d66-43b1-a60c-b089eefe329a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                576       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2689 (10.50 KB)\n",
            "Trainable params: 2689 (10.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=16, validation_split=0.1, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edY2j8SjGWsp",
        "outputId": "e0488581-d701-418b-f479-d68201167b2b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "929/929 [==============================] - 4s 3ms/step - loss: 0.6623 - val_loss: 0.4727\n",
            "Epoch 2/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.3898 - val_loss: 0.4599\n",
            "Epoch 3/100\n",
            "929/929 [==============================] - 3s 3ms/step - loss: 0.3547 - val_loss: 0.3948\n",
            "Epoch 4/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.3552 - val_loss: 0.3564\n",
            "Epoch 5/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.3449 - val_loss: 0.3480\n",
            "Epoch 6/100\n",
            "929/929 [==============================] - 5s 5ms/step - loss: 0.3198 - val_loss: 0.3520\n",
            "Epoch 7/100\n",
            "929/929 [==============================] - 4s 4ms/step - loss: 0.3153 - val_loss: 0.3361\n",
            "Epoch 8/100\n",
            "929/929 [==============================] - 4s 5ms/step - loss: 0.3100 - val_loss: 0.3385\n",
            "Epoch 9/100\n",
            "929/929 [==============================] - 4s 4ms/step - loss: 0.3069 - val_loss: 0.3342\n",
            "Epoch 10/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.3146 - val_loss: 0.3288\n",
            "Epoch 11/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2981 - val_loss: 0.3193\n",
            "Epoch 12/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2933 - val_loss: 0.3207\n",
            "Epoch 13/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2885 - val_loss: 0.3271\n",
            "Epoch 14/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2903 - val_loss: 0.3224\n",
            "Epoch 15/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2841 - val_loss: 0.3194\n",
            "Epoch 16/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.2834 - val_loss: 0.3211\n",
            "Epoch 17/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2783 - val_loss: 0.3231\n",
            "Epoch 18/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2793 - val_loss: 0.3030\n",
            "Epoch 19/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2785 - val_loss: 0.3084\n",
            "Epoch 20/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2793 - val_loss: 0.3071\n",
            "Epoch 21/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2746 - val_loss: 0.3067\n",
            "Epoch 22/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2741 - val_loss: 0.3106\n",
            "Epoch 23/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.2713 - val_loss: 0.3005\n",
            "Epoch 24/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2715 - val_loss: 0.2958\n",
            "Epoch 25/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2711 - val_loss: 0.2995\n",
            "Epoch 26/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2670 - val_loss: 0.2947\n",
            "Epoch 27/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2680 - val_loss: 0.2997\n",
            "Epoch 28/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2629 - val_loss: 0.2979\n",
            "Epoch 29/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2644 - val_loss: 0.2904\n",
            "Epoch 30/100\n",
            "929/929 [==============================] - 3s 3ms/step - loss: 0.2612 - val_loss: 0.2917\n",
            "Epoch 31/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2657 - val_loss: 0.3083\n",
            "Epoch 32/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2636 - val_loss: 0.2958\n",
            "Epoch 33/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2597 - val_loss: 0.2874\n",
            "Epoch 34/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2572 - val_loss: 0.2999\n",
            "Epoch 35/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2570 - val_loss: 0.2901\n",
            "Epoch 36/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2544 - val_loss: 0.2899\n",
            "Epoch 37/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.2565 - val_loss: 0.2967\n",
            "Epoch 38/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2546 - val_loss: 0.2862\n",
            "Epoch 39/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2536 - val_loss: 0.2882\n",
            "Epoch 40/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2537 - val_loss: 0.3043\n",
            "Epoch 41/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2524 - val_loss: 0.2893\n",
            "Epoch 42/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2503 - val_loss: 0.2849\n",
            "Epoch 43/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2491 - val_loss: 0.2910\n",
            "Epoch 44/100\n",
            "929/929 [==============================] - 3s 3ms/step - loss: 0.2501 - val_loss: 0.2928\n",
            "Epoch 45/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2489 - val_loss: 0.2855\n",
            "Epoch 46/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2478 - val_loss: 0.2901\n",
            "Epoch 47/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2461 - val_loss: 0.2856\n",
            "Epoch 48/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2459 - val_loss: 0.2979\n",
            "Epoch 49/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2453 - val_loss: 0.2815\n",
            "Epoch 50/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2458 - val_loss: 0.2815\n",
            "Epoch 51/100\n",
            "929/929 [==============================] - 3s 3ms/step - loss: 0.2437 - val_loss: 0.2901\n",
            "Epoch 52/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2433 - val_loss: 0.2793\n",
            "Epoch 53/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2410 - val_loss: 0.2788\n",
            "Epoch 54/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2400 - val_loss: 0.2763\n",
            "Epoch 55/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2383 - val_loss: 0.2938\n",
            "Epoch 56/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2401 - val_loss: 0.2869\n",
            "Epoch 57/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2390 - val_loss: 0.2824\n",
            "Epoch 58/100\n",
            "929/929 [==============================] - 4s 4ms/step - loss: 0.2372 - val_loss: 0.2782\n",
            "Epoch 59/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2380 - val_loss: 0.2754\n",
            "Epoch 60/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2376 - val_loss: 0.2740\n",
            "Epoch 61/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2372 - val_loss: 0.2822\n",
            "Epoch 62/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2352 - val_loss: 0.2891\n",
            "Epoch 63/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2372 - val_loss: 0.2789\n",
            "Epoch 64/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2351 - val_loss: 0.2801\n",
            "Epoch 65/100\n",
            "929/929 [==============================] - 3s 3ms/step - loss: 0.2338 - val_loss: 0.2753\n",
            "Epoch 66/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2349 - val_loss: 0.2830\n",
            "Epoch 67/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2344 - val_loss: 0.2859\n",
            "Epoch 68/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2323 - val_loss: 0.2789\n",
            "Epoch 69/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2311 - val_loss: 0.2790\n",
            "Epoch 70/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2335 - val_loss: 0.2884\n",
            "Epoch 71/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2307 - val_loss: 0.2816\n",
            "Epoch 72/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2308 - val_loss: 0.2844\n",
            "Epoch 73/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2301 - val_loss: 0.2860\n",
            "Epoch 74/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2302 - val_loss: 0.2741\n",
            "Epoch 75/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2299 - val_loss: 0.2907\n",
            "Epoch 76/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2292 - val_loss: 0.2869\n",
            "Epoch 77/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2284 - val_loss: 0.2857\n",
            "Epoch 78/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2289 - val_loss: 0.2797\n",
            "Epoch 79/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.2273 - val_loss: 0.2833\n",
            "Epoch 80/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2295 - val_loss: 0.2782\n",
            "Epoch 81/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2263 - val_loss: 0.2808\n",
            "Epoch 82/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2271 - val_loss: 0.2772\n",
            "Epoch 83/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2273 - val_loss: 0.2792\n",
            "Epoch 84/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2283 - val_loss: 0.2771\n",
            "Epoch 85/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2280 - val_loss: 0.2733\n",
            "Epoch 86/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.2232 - val_loss: 0.2765\n",
            "Epoch 87/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2240 - val_loss: 0.2811\n",
            "Epoch 88/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2248 - val_loss: 0.2727\n",
            "Epoch 89/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2241 - val_loss: 0.2882\n",
            "Epoch 90/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2238 - val_loss: 0.2781\n",
            "Epoch 91/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2220 - val_loss: 0.2774\n",
            "Epoch 92/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2219 - val_loss: 0.2794\n",
            "Epoch 93/100\n",
            "929/929 [==============================] - 2s 3ms/step - loss: 0.2215 - val_loss: 0.2824\n",
            "Epoch 94/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2207 - val_loss: 0.2691\n",
            "Epoch 95/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2197 - val_loss: 0.2797\n",
            "Epoch 96/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2209 - val_loss: 0.2767\n",
            "Epoch 97/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2208 - val_loss: 0.2719\n",
            "Epoch 98/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2207 - val_loss: 0.2792\n",
            "Epoch 99/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2211 - val_loss: 0.2822\n",
            "Epoch 100/100\n",
            "929/929 [==============================] - 2s 2ms/step - loss: 0.2193 - val_loss: 0.2755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Test Loss:\", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D8uXpbDGZYz",
        "outputId": "74e5547b-278c-401c-9ba8-f46da8d05628"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 0s 1ms/step - loss: 0.2687\n",
            "Test Loss: 0.2687022089958191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJSY9VY2GbNJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}